{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d3e813",
   "metadata": {},
   "source": [
    "# BagOfWords approach for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c7ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3998a3b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[43mstop_words\u001b[49m\u001b[38;5;241m.\u001b[39mENGLISH_STOP_WORDS\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Function for basic cleaning/preprocessing texts\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean\u001b[39m(doc):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Removal of punctuation marks (.,/\\][{} etc) and numbers\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words = stop_words.ENGLISH_STOP_WORDS\n",
    "#Function for basic cleaning/preprocessing texts\n",
    "def clean(doc):\n",
    "    # Removal of punctuation marks (.,/\\][{} etc) and numbers\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    # Removal of stopwords\n",
    "    doc = \" \".join([token for token in doc.split() if token not in stop_words])\n",
    "    return doc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992b77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS for text classification\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f050fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"E:\\\\mladhd\\\\datasets\\\\text\\\\data_clean_large.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b84a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvFile, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be7840da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>© From your Google Drive Interview-Mode BK99 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S Cc @ amazon.com/gp/bestsellers/?ref_=nav_cs_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      0  © From your Google Drive Interview-Mode BK99 S...\n",
       "1      1  S Cc @ amazon.com/gp/bestsellers/?ref_=nav_cs_..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c440a353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     NaN\n",
       "class      0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb2f8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()#(preprocessor=clean)\n",
    "# Create sample set of documents\n",
    "docs = df.text.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76b775d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 363)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the bag-of-words model\n",
    "bag = vectorizer.fit_transform(docs)\n",
    "bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8ba82d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get unique words / tokens found in all the documents. The unique words / tokens represents\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# the features\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "# Get unique words / tokens found in all the documents. The unique words / tokens represents\n",
    "# the features\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the indices with each unique word\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the numerical feature vector\n",
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d68291",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "bag_tfidf = tfidf_transformer.fit_transform(bag)\n",
    "bag_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9dbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data\n",
    "X = bag_tfidf.to_numpy()\n",
    "y = df[\"class\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20accfe",
   "metadata": {},
   "source": [
    "## Choose a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Logistic Regression\" # \"Logistic Regression\" or \"Multinomial Naive Bayes\"\n",
    "model = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87da3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f67370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predictions\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy, precision, recall and f1-score\n",
    "print(\"Model accuracy: \", metrics.accuracy_score(y_test, y_predict))\n",
    "print(\"Model precision: \", metrics.precision_score(y_test, y_predict))\n",
    "print(\"Model recall: \", metrics.recall_score(y_test, y_predict))\n",
    "print(\"Model f1-score: \", metrics.f1_score(y_test, y_predict))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c964fa5b",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c676485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the feature names to an empty list\n",
    "feat_impts = [vectorizer.get_feature_names()]\n",
    "#For all the models save the feature importances in the #list.estimators_ would give the internal models used by the #multioutput regressor\n",
    "for clf in model.estimators_:\n",
    "    feat_impts.append(clf.coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c975a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the coefficients in a dataframe\n",
    "df_feats_impts = pd.DataFrame(np.transpose(np.array(feat_impts)), columns = [\"focused\",\"distracted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Individual Feature Importance table by sorting on specific toxic-type column and selecting top 5 words\n",
    "focused_fi = df_feats_impts[[\"word\",\"focused\"]].sort_values(by = \"focused\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Individual Feature Importance table by sorting on specific toxic-type column and selecting top 5 words\n",
    "distracted = df_feats_impts[[\"word\",\"focused\"]].sort_values(by = \"focused\", ascending = False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_mladhd]",
   "language": "python",
   "name": "conda-env-env_mladhd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
